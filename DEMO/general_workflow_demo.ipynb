{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# âœ¨ ClassifAI Demo âœ¨\n",
    "\n",
    "---\n",
    "\n",
    "#### ClassifAI is a tool to help in the creation and serving of searchable vector databases, for text classification tasks.\n",
    "\n",
    "#### There are three main concerns involved in making a live, searchable, vector database for your applications:\n",
    "\n",
    "1. **Vectorising** - The creation of vectors from text  \n",
    "2. **Indexing** - The creation of a vector store, converting many texts to vectors \n",
    "3. **Serving** - Wrapping the Vector Store in an API to make it searchable from endpoints\n",
    "\n",
    "#### ClassifAI provides three key modules to address these, letting you build Rest-API search systems from your text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup (install dependencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## if using pip\n",
    "# % pip install -e \"..[huggingface]\"\n",
    "\n",
    "## if using uv\n",
    "# ! uv sync --extra huggingface\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorising\n",
    "\n",
    "![Vectoriser_image](files/vectoriser.png)\n",
    "\n",
    "#### We provide several vectoriser classes that you can use to convert text to embeddings/vectors;\n",
    "```python\n",
    "from classifai.vectorisers import (\n",
    "    HuggingFaceVectoriser,\n",
    "    GcpVectoriser,\n",
    "    OllamaVectoriser\n",
    ")\n",
    "```\n",
    "\n",
    "If none of these match your needs, you can define a custom vectoriser by extending our base class;\n",
    "```python\n",
    "from classifai.vectorisers import VectoriserBase\n",
    "```\n",
    "We'll discuss that option in more detail after this initial demo.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialising a vectoriser:\n",
    "\n",
    "We'll download and use a locally-hosted, small HuggingFace model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifai.vectorisers import HuggingFaceVectoriser\n",
    "\n",
    "# Our embedding model is pulled down from HuggingFace, or used straight away if previously downloaded\n",
    "# This also works with many different huggingface models!\n",
    "vectoriser = HuggingFaceVectoriser(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# The `.transform()` method converts text to a vector, or several texts to an array of vectors\n",
    "my_first_vector = vectoriser.transform(\"classifai is a great tool for building AI applications.\")\n",
    "list_of_vectors = vectoriser.transform([\"bag-of-words isn't as good as classifAI\", \"tf-idf isn't as good as classifAI\"])\n",
    "\n",
    "\n",
    "my_first_vector.shape, list_of_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The VectorStore class creates a vector database by converting a set of labelled texts to embeddings, using an associated Vectoriser.\n",
    "#### Once created, it can be 'searched', using the vectoriser to embed queries as vectors and calculate their semantic similarity to the labelled texts in the VectorStore\n",
    "![VectorStore_image](files/VectorStore.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifai.indexers import VectorStore\n",
    "\n",
    "my_vector_store = VectorStore(\n",
    "    file_name=\"data/testdata.csv\",\n",
    "    data_type=\"csv\",\n",
    "    vectoriser=vectoriser,\n",
    "    meta_data={\"colour\": str, \"language\": str},\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once created, you can search the vector store by calling the .search() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vector_store.search(\"What colour is snow?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can search multiple queries at once (and specify how many results you want per query)\n",
    "my_vector_store.search([\"What colour is snow?\", \"what is inside books\"], n_results=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can also search by id by calling the .reverse_search method on the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vector_store.reverse_search([\"1100\", \"1056\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving up your VectorStore!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So you've created a VectorStore, with your chosen Vectoriser; that makes vectors and you can search it...\n",
    "\n",
    "#### *Now, how do I host it so others can use it?*\n",
    "\n",
    "![Server_Image](files/servers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To Serve an api all we need to do is create a Vectorizer, and a Vector store, then pass it into out server `start_api` function for it to begin serving fast api endpoints for out VectorStore.\n",
    "#### We have a demo script at `./DEMO/general_workflow_serve.py`\n",
    "#### Here's a an example of what it does\n",
    "```python\n",
    "##### first we load the vectoriser used in the vectorstore creation\n",
    "from classifai.indexers import VectorStore\n",
    "from classifai.servers import start_api\n",
    "from classifai.vectorisers import HuggingFaceVectoriser\n",
    "\n",
    "# Our embedding model is pulled down from HuggingFace, or used straight away if previously downloaded\n",
    "# This also works with many different huggingface models!\n",
    "vectoriser = HuggingFaceVectoriser(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "#### now we can load the vectorstore back in without having to create it again\n",
    "loaded_vectorstore = VectorStore.from_filespace(\"./DEMO/testdata\", vectoriser)\n",
    "\n",
    "\n",
    "#### look wow! you can search it straight away cause it was loaded back in\n",
    "\n",
    "print(f\"Test search {loaded_vectorstore.search('did the quick brown fox jump over the log?')}\")\n",
    "\n",
    "\n",
    "#### and finally, its easy to search your vectorstore via a restAPI service, just run:\n",
    "start_api([loaded_vectorstore], endpoint_names=[\"my_vectorstore\"])\n",
    "\n",
    "# Look at https://0.0.0.0:8000/docs to see the Swagger API documentation and test in the browser\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To serve the demo simply run `./DEMOS/general_workflow_serve.py`  to see it in action!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roundup\n",
    "\n",
    "#### That's it - you should now have made a running restAPI service that lets you search the texts you indexed in the test CSV.\n",
    "\n",
    "#### Check out the GitHub repo, where there is a quick start guide in the Readme.md ðŸ˜Š"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
