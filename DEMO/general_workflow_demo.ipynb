{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# âœ¨ ClassifAI Demo âœ¨\n",
    "\n",
    "---\n",
    "\n",
    "#### ClassifAI is a tool to help in the creation and serving of searchable vector databases, for text classification tasks.\n",
    "\n",
    "#### There are three main concerns involved in making a live, searchable, vector database for your applications:\n",
    "\n",
    "1. **Vectorising** - The creation of vectors from text  \n",
    "2. **Indexing** - The creation of a vector store, converting many texts to vectors \n",
    "3. **Serving** - Wrapping the Vector Store in an API to make it searchable from endpoints\n",
    "\n",
    "#### ClassifAI provides three key modules to address these, letting you build Rest-API search systems from your text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation (pre-release)\n",
    "\n",
    "`Classifai` is currently in **pre-release** and is **not yet published on PyPI**.  \n",
    "This section describes how to install the packaged **wheel** from the projectâ€™s public GitHub Releases so that you can follow through this DEMO and try the code yourself.\n",
    "\n",
    "### 1) Create and activate a virtual environment in command line\n",
    "\n",
    "#### Using `pip` + `venv`\n",
    "Create a virtual environment:\n",
    "\n",
    "```bash\n",
    "python -m venv .venv\n",
    "```\n",
    "\n",
    "#### Using `UV`\n",
    "Create a virtual environment:\n",
    "\n",
    "```bash\n",
    "uv venv\n",
    "```\n",
    "\n",
    "Activate the created environment with \n",
    "\n",
    "(macOS / Linux):\n",
    "```bash\n",
    "source .venv/bin/activate\n",
    "```\n",
    "Activate it (Windows):\n",
    "```bash\n",
    "source .venv/Scripts/activate\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2) Install the pre-release wheel\n",
    "\n",
    "#### Using `pip`\n",
    "```bash\n",
    "pip install \"https://github.com/datasciencecampus/classifai/releases/download/v0.2.1/classifai-0.2.1-py3-none-any.whl\"\n",
    "```\n",
    "\n",
    "#### Using `uv`\n",
    "```bash\n",
    "uv pip install \"https://github.com/datasciencecampus/classifai/releases/download/v0.2.1/classifai-0.2.1-py3-none-any.whl\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3) Install optional dependencies (`[huggingface]`)\n",
    "\n",
    "Finally, for this demo we will be using the Huggingface Library to download embedding models - we therefore need an optional dependency of the Classifai Pacakge:\n",
    "\n",
    "#### Using `pip`\n",
    "```bash\n",
    "pip install \"classifai[huggingface]\"\n",
    "```\n",
    "\n",
    "#### Using `uv pip`\n",
    "```bash\n",
    "uv pip install \"classifai[huggingface]\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the step one virtual environemnt is set up and actiavted and ready in the terminal, run the following commands to install the classifai package and the huggingface dependencies.\n",
    "## PIP\n",
    "#!pip install \"https://github.com/datasciencecampus/classifai/releases/download/v0.2.1/classifai-0.2.1-py3-none-any.whl\"\n",
    "#!pip install \"classifai[huggingface]\"\n",
    "\n",
    "## UV\n",
    "#!uv pip install \"https://github.com/datasciencecampus/classifai/releases/download/v0.2.1/classifai-0.2.1-py3-none-any.whl\"\n",
    "#!uv pip install \"classifai[huggingface]\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note! :\n",
    "\n",
    "You may need to install the ipykernel python package to run Notebook cells with your Python environment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ipykernel\n",
    "\n",
    "#!uv pip install ipykernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### If you can run the following cell in this notebook, you should be good to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifai.vectorisers import HuggingFaceVectoriser\n",
    "\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo Data \n",
    "\n",
    "\n",
    "This demo uses a mock dataset that is freely available on the ClassifAI repo, if yo have not downloaded the entire DEMO folder to run this notebook, the minimum data you require is the `DEMO/data/testdata.csv` file, which you should place in your working directory in a `DEMO` folder - (or you can just change the filepath later in this demo notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorising\n",
    "\n",
    "![Vectoriser_image](files/vectoriser.png)\n",
    "\n",
    "#### We provide several vectoriser classes that you can use to convert text to embeddings/vectors;\n",
    "```python\n",
    "from classifai.vectorisers import (\n",
    "    HuggingFaceVectoriser,\n",
    "    GcpVectoriser,\n",
    "    OllamaVectoriser\n",
    ")\n",
    "```\n",
    "\n",
    "If none of these match your needs, you can define a custom vectoriser by extending our base class;\n",
    "```python\n",
    "from classifai.vectorisers import VectoriserBase\n",
    "```\n",
    "\n",
    "There is another DEMO notebook, called `custom_vectoriser.ipynb` which provides a walk through of extending the base class to make a custom TF-IDF Vectoriser model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialising a vectoriser:\n",
    "\n",
    "We'll download and use a locally-hosted, small HuggingFace model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our embedding model is pulled down from HuggingFace, or used straight away if previously downloaded\n",
    "# This also works with many different huggingface models!\n",
    "vectoriser = HuggingFaceVectoriser(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# The `.transform()` method converts text to a vector, or several texts to an array of vectors\n",
    "my_first_vector = vectoriser.transform(\"classifai is a great tool for building AI applications.\")\n",
    "list_of_vectors = vectoriser.transform([\"bag-of-words isn't as good as classifAI\", \"tf-idf isn't as good as classifAI\"])\n",
    "\n",
    "\n",
    "my_first_vector.shape, list_of_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Vectoriser API is simple; it takes in a string or a list and strings, and returns a Numpy ndArray object.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The VectorStore class creates a vector database by converting a set of labelled texts to embeddings, using an associated Vectoriser.\n",
    "#### Once created, it can be 'searched', using the vectoriser to embed queries as vectors and calculate their semantic similarity to the labelled texts in the VectorStore\n",
    "![VectorStore_image](files/VectorStore.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifai.indexers import VectorStore\n",
    "\n",
    "my_vector_store = VectorStore(\n",
    "    file_name=\"data/testdata.csv\",\n",
    "    data_type=\"csv\",\n",
    "    vectoriser=vectoriser,\n",
    "    meta_data={\"colour\": str, \"language\": str},\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VectorStore Data Objects\n",
    "\n",
    "We've created a VectorStore with the code above. As we'll see in the next few code cells, we can 'search' the vector store by passing a 'query' to it to get top K results that are similar to the query.\n",
    "\n",
    "<b> But how do we pass the queries to the VectorStore? </b>\n",
    "\n",
    "ClassifAI provides specialised Pandas datframe objects for each kind of request that can be made to the VectorStore - this provides a clear and consistent interface for sending data to the VectorStore (and also receiving data from the vectorstore). \n",
    "\n",
    "First lets look at the `VectorStoreSearchInput` data object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifai.indexers.dataclasses import VectorStoreSearchInput\n",
    "\n",
    "input_data = VectorStoreSearchInput(\n",
    "    {\"id\": [1, 2], \"query\": [\"What is the colour of the sky?\", \"What language is spoken in Brazil?\"]}\n",
    ")\n",
    "\n",
    "input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above cell, we're building the object that the VectorStore takes in to do the search process. Our input expects two columns of data, id and query, as above. And this data can be passed to our VectorStoreSearchInput class, as a dictionary <b> or alreadt as a Pandas dataframe. </b>\n",
    "\n",
    "If you try to remove some of the data, say the 'id' column. Our data class object will inform you that you're missing some data. In this sense the data classes keep you right when working with the Package.\n",
    "\n",
    "\n",
    "Look at the type of the input_data object we created, notice that it is not of type Pandas, but our own custom type. Under the hood this is doing the additional work to validate the data your passing in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once created, you can search the vector store by calling the .search() method\n",
    "\n",
    "Actually calling the VectorStore is very simple once we have that data object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vector_store.search(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you could pass your query(s) inline with the object as well: (AND specify how many results you want per query)\n",
    "my_vector_store.search(VectorStoreSearchInput({\"id\": [999], \"query\": \"is the desert large?\"}), n_results=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can also search by id by calling the .reverse_search method on the object\n",
    "\n",
    "We call a different method for this on the vectorstore <i>reverse_search()</i> - and it has its own data class object - `VectorStoreReverseSearchInput`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifai.indexers.dataclasses import VectorStoreReverseSearchInput\n",
    "\n",
    "input_data_2 = VectorStoreReverseSearchInput({\"id\": [\"1\", \"2\"], \"doc_id\": [\"1100\", \"1056\"]})\n",
    "\n",
    "my_vector_store.reverse_search(input_data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With reverse search you can do partial matching!\n",
    "use the `partial_match` flag to check if the documents **Starts with** our query id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_3 = VectorStoreReverseSearchInput({\"id\": [\"1\", \"2\"], \"doc_id\": [\"1100\", \"105\"]})\n",
    "\n",
    "my_vector_store.reverse_search(input_data_3, partial_match=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use n_results to limit the amount of results per-item\n",
    "\n",
    "my_vector_store.reverse_search(input_data_3, n_results=2, partial_match=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VectorStore Embed method\n",
    "\n",
    "Its also possible to get the vector embeddings for each from some input text or queries by calling the VectorStore <i>.embed()</i> method.\n",
    "\n",
    "Once again, this method has its own data class to inferace with: `VectorStoreEmbedInput`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifai.indexers.dataclasses import VectorStoreEmbedInput\n",
    "\n",
    "input_data_3 = VectorStoreEmbedInput(\n",
    "    {\n",
    "        \"id\": [\"a\", \"b\"],\n",
    "        \"text\": [\n",
    "            \"The quick brown fox jumps over the lazy dog.\",\n",
    "            \"Classifai is an amazing library for AI applications.\",\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "my_vector_store.embed(input_data_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Output Dataclass Objects!\n",
    "\n",
    "We've seen an <b>input data classes for each of our VectorStore's methods</b>: embed, search, and reverse Search...\n",
    "\n",
    "but these VectorStore methods also have <i> output dataclass objects <i> too, which provide a consistent output interface for you to work with. \n",
    "\n",
    "\n",
    "#### In all cases, for output and input data class objects, the column names are specific:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The VectorStoreEmbedOutput object:\n",
    "\n",
    "embed_output = my_vector_store.embed(input_data_3)\n",
    "print(type(embed_output))\n",
    "embed_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The VectorStoreReverseSearchOutput object:\n",
    "\n",
    "reverse_search_output = my_vector_store.reverse_search(input_data_2)\n",
    "print(type(reverse_search_output))\n",
    "reverse_search_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The VectorStoreSearchOutput object:\n",
    "\n",
    "search_output = my_vector_store.search(input_data)\n",
    "print(type(search_output))\n",
    "search_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating Data Class Objects\n",
    "\n",
    "The dataclass objects are central to passing and receiving data from the VectorStore. You can therefore instantiate them with the traditional init method, or directly with the method <i>.from_data</i> which achieves the same affect. \n",
    "\n",
    "\n",
    "However in future updates we intend to add more methods, for example 'from_csv' which we anticipate would allow users process large files of queries more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_4 = VectorStoreSearchInput({\"id\": [3], \"query\": [\"What is the colour of grass?\"]})\n",
    "\n",
    "### IS THE SAME AS:\n",
    "\n",
    "input_data_5 = VectorStoreSearchInput.from_data({\"id\": [3], \"query\": [\"What is the colour of grass?\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving up your VectorStore!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So you've created a VectorStore, with your chosen Vectoriser; that makes vectors and you can search it...\n",
    "\n",
    "#### *Now, how do I host it so others can use it?*\n",
    "\n",
    "![Server_Image](files/servers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To Serve an api all we need to do is create a Vectorizer, and a Vector store, then pass it into out server `start_api` function for it to begin serving fast api endpoints for out VectorStore.\n",
    "#### We have a demo script at `./DEMO/general_workflow_serve.py`\n",
    "#### Here's a an example of what it does\n",
    "```python\n",
    "##### first we load the vectoriser used in the vectorstore creation\n",
    "from classifai.indexers import VectorStore\n",
    "from classifai.servers import start_api\n",
    "from classifai.vectorisers import HuggingFaceVectoriser\n",
    "\n",
    "# Our embedding model is pulled down from HuggingFace, or used straight away if previously downloaded\n",
    "# This also works with many different huggingface models!\n",
    "vectoriser = HuggingFaceVectoriser(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "#### now we can load the vectorstore back in without having to create it again\n",
    "loaded_vectorstore = VectorStore.from_filespace(\"./DEMO/testdata\", vectoriser)\n",
    "\n",
    "\n",
    "#### look wow! you can search it straight away cause it was loaded back in\n",
    "\n",
    "print(f\"Test search {loaded_vectorstore.search('did the quick brown fox jump over the log?')}\")\n",
    "\n",
    "\n",
    "#### and finally, its easy to search your vectorstore via a restAPI service, just run:\n",
    "start_api([loaded_vectorstore], endpoint_names=[\"my_vectorstore\"])\n",
    "\n",
    "# Look at https://0.0.0.0:8000/docs to see the Swagger API documentation and test in the browser\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To serve the demo simply run `./DEMOS/general_workflow_serve.py`  to see it in action!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roundup\n",
    "\n",
    "#### That's it - you should now have made a running restAPI service that lets you search the texts you indexed in the test CSV.\n",
    "\n",
    "#### Check out the GitHub repo, where there is a quick start guide in the Readme.md ðŸ˜Š"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classifai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
