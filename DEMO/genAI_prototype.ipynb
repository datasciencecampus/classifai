{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GEN AI Workflow Notebook ✨✨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ClassifAI allows users to create vector databases from text datasets, search those vector datasets in an ad-hoc retrieval manner, and deploy this pipeline as a restAPI service using FastAPI to perform AI assisted classification tasks.\n",
    "\n",
    "\n",
    "An recent emergent AI field is Retrieval Augmented Generation (RAG) where text generation models that traditionally respond to a user 'prompt', first retrieve relvant infomration from a vector database via adhoc retrieval processes, and use those serach results as context to generate an answer for the original user prompt.\n",
    "\n",
    "#### This notebook shows how RAG can be implemented into our ClassifAI utilising its existing retrieval augmentation capabilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ClassifAIs existing retrieval setup\n",
    "\n",
    "![Server_Image](files/servers.png)\n",
    "\n",
    "#### The other modules of ClassifAI provide 3 core classes that work together to:\n",
    "\n",
    "1. Vectorisers, to create embeddings,\n",
    "2. Vectorstores, to create datgabsees of vectors and the ability to searc/query those database\n",
    "3. RestAPI, to deploy a rest api service on a server to allow connections that search the created vector databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install \"classifai[gcp]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We need to first set up a traditional ClassifAI pipeline that can provide search/classification results for our generative model to use as context...\n",
    "\n",
    "\n",
    "All of the following code is part of our standard ClassifAI setupm, and is a short demo of how you can create a semantic search classification system. <b>Check out our general_workflow_demo.ipynb notebook for a walkthrough of the content of these cells!</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifai.indexers import VectorStore\n",
    "from classifai.vectorisers import GcpVectoriser\n",
    "\n",
    "vectoriser = GcpVectoriser(\n",
    "    project_id=\"<your-gcp-project-id>\",\n",
    "    model_name=\"text-embedding-004\",\n",
    "    task_type=\"CLASSIFICATION\",\n",
    ")\n",
    "\n",
    "\n",
    "my_vector_store = VectorStore(\n",
    "    file_name=\"./data/fake_soc_dataset.csv\",  # demo csv file from the classifai package repo! (try some of our other DEMO/data datasets)\n",
    "    data_type=\"csv\",\n",
    "    vectoriser=vectoriser,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We've set up our semantic search classification system\n",
    "\n",
    "The following cell runs the 'search' method of the vectorstore, which will take a query for our created vectorstore and return the top k (n_results) most similar samples stored in the vectorstore. This is an example of our exisiting retrieval capabilities with the ClassifAI package. \n",
    "\n",
    "This retrieved set can then be used to make a final classification decision, by some method such as:\n",
    "- automatically choosing the top ranked item, \n",
    "- a human in the loop physically looking at the retrieved candidates making the decision,\n",
    "- by using a generative AI agent to assess the candidate lists and making a final decison... more on that later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vector_store.search(\"dairy famer that sells milk\", n_results=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a RAG Agent\n",
    "\n",
    "With a way of getting context information for a query/prompt we can now instantiate a generative model\n",
    "\n",
    "\n",
    "![Rag_Image](files/agent.png) \n",
    "\n",
    "\n",
    "In essence, the RAG agent has a .generate method which accepts a string query. It internally calls the associated vectorstore's search method using that query provided by the user. The original user query and the vectorstore results are used to generate a response.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To instantiate the object it takes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifai.generators import RagAgent_GCP\n",
    "\n",
    "my_agent = RagAgent_GCP(\n",
    "    project_id=\"<your-gcp-project-id>\",\n",
    "    model_name=\"gemini-2.5-flash\",\n",
    "    vectorStore=my_vector_store,\n",
    "    task_type=\"classification\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similar to the Vectorsiser it has a transform method -\n",
    "\n",
    "this executes a vector store search, then uses that ranking and the user query to generate a response in line with the TASK_TYPE.\n",
    "\n",
    "In the above case we are using the <b>\"classification\"</b> task type which tells the model [using a system prompt](https://docs.cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/system-instructions) which guides our model in what to do with our retrieved ranking and user prompt/input. \n",
    "\n",
    "We also currently provide a <b>\"summarization\"</b> task type which uses a different system prompt we've built that instructs the model to provide a laymans summary of the content of the top k retrieved results. We won't show that in this demo though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_agent.transform(\"apple farmer and other farming types\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thats it!\n",
    "\n",
    "You can see in the above cell that my_agent.transform()  returns a 'text' entry and a 'ranking' entry. The 'text' entry contains a string \"classification: X\", where X will be replaced by the final classification decision that the agent decided was correct given the user query and retreived ranking.\n",
    "\n",
    "Check out the general_worfklow notebook to see how VectorStore models AND Generative RAG models can be deployed. Both can be passed to the start_api function, to deploy these models in a restAPI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
