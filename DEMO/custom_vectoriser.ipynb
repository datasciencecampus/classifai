{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Your Own Vectoriser\n",
    "\n",
    "The ClassifAI Package is organised into three key modules, which work together to help you build and host a search engine. These are:\n",
    "\n",
    "1. Vectorisers - Models for converting from text to vectors\n",
    "2. Indexers - Classes for building vector stores from text datasets that you can search\n",
    "3. Servers - Allows you to deploy a VectorStore with a RestAPI interface on a server\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook showcases how to create your own custom Vectoriser - we already provide several out-of-the-box Vectoriser classes for converting text to embeddings that essentially provide shortcuts for several common methods i.e. gcloud embedding services, Huggingface models, and Ollama. \n",
    "\n",
    "But what if you wanted to make your own custom embedding vectoriser model, that uses your own fancy embedding method...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this Notebook...\n",
    "\n",
    "We will show:\n",
    "* The core workings of the Vectotiser Class and its responsibilities\n",
    "* How to create a custom One-Hot encoding vectoriser from scratch that will work seemlessly with the rest of the ClassifAI Package\n",
    "* the custom One-Hot Encoding vectoriser being used with the Indexer module to create and search a VectorStore!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Vectoriser\n",
    "\n",
    "IMAGE GOES HERE\n",
    "\n",
    "As seen above, Vectorisers' sole responsibility is to convert text to a vector representation. Each Vectoriser class must implement a transform() method that will:\n",
    "\n",
    "1. accept a string or list of N strings as an argument\n",
    "2. return a numpy array of dimension [N,Y] where N matches the number of input strings, and Y is the embedding dimension)\n",
    "\n",
    "By enforcing this interface, of having a single 'transform()' method for every vectoriser, it means that the Indexers and Servers modules cna predictably work with any Vectoriser object to perform the various search engine functions of this Package. \n",
    "\n",
    "Therefore, all a user has to consider when building their own vectoriser is the logic of this transform() method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets build an One-Hot-Encoding Vectoriser\n",
    "\n",
    "One-hot encoding is a simple method of converting from text to vector format. Each element in a one-hot encoded vector represents the presence or absence of a particular word in a large vocabulary. Therefore the length of the vector represents the size of the vocabulary. Each word in a sentence is transformed so that the the corresponding positional elements in the one-hot encoding vector will be set to 1. So, all sentences that contain the word 'dog' should all have the same element i of their vectors set to 1, which is the element that represents the presence of the word dog. Finally, if the converted sentence only contains 5 words, then the vector will only have 5 non-zero elements at most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we're going to use scikit learns countvectoriser to create our one hot embeddings\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-hot encoding vectoriser implememntation.\n",
    "\n",
    "# 1. Class must inherit from the VectoriserBase class.\n",
    "# 2. The class must implement the transform method.\n",
    "\n",
    "\n",
    "#importing sklearns CountVectorizer, a common library tool for vectorisation.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from classifAI_API.vectorisers import VectoriserBase\n",
    "import numpy as np\n",
    "\n",
    "class OneHotVectoriser(VectoriserBase):\n",
    "    def __init__(self, vocabulary: list[str]):\n",
    "        if not vocabulary:\n",
    "            raise ValueError(\"Vocabulary cannot be empty.\")\n",
    "        self.vectorizer = CountVectorizer(binary=True, vocabulary=vocabulary)\n",
    "\n",
    "    def transform(self, texts: str | list[str]) -> np.ndarray:\n",
    "\n",
    "        #checking if the input is a string and converting to a list if so\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "\n",
    "        #we add some light type checking to make sure the input is correct\n",
    "        if not isinstance(texts, list):\n",
    "            raise TypeError(\"Input must be a string or a list of strings.\")\n",
    "\n",
    "        # Generate one-hot encodings using the CountVectorizer from Scikit-learn\n",
    "        one_hot_matrix = self.vectorizer.transform(texts).toarray()\n",
    "        return one_hot_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've written our custom vectoriser to accept a vocabulary as an argument during instantiation.\n",
    "\n",
    "You could hardcode a specific vocabulary, but doing it this way would make our class reusable so that we could instantiate different OneHotVectorisers with different vocabularies\n",
    "\n",
    "We're going to download and use Google's 10,000 most common words - a very well known file - as our vocab for our first custom one hot encoder model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved as google-10000-english.txt\n",
      "Vocabulary loaded with 10000 words.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "### First we need to download the vocabulary\n",
    "\n",
    "# Check if the file already exists locally\n",
    "if not os.path.exists(\"google-10000-english.txt\"):\n",
    "\n",
    "    #download file \n",
    "    url = \"https://raw.github.com/first20hours/google-10000-english/master/google-10000-english.txt\"\n",
    "    # Path to save the file locally\n",
    "    output_file = \"google-10000-english.txt\"\n",
    "\n",
    "    # Download the file\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(output_file, \"w\") as file:\n",
    "            file.write(response.text)\n",
    "        print(f\"File downloaded and saved as {output_file}\")\n",
    "    else:\n",
    "        print(f\"Failed to download file. HTTP Status Code: {response.status_code}\")\n",
    "\n",
    "\n",
    "\n",
    "# Load vocabulary from the downloaded file\n",
    "with open(\"google-10000-english.txt\", \"r\") as file:\n",
    "    vocabulary = [line.strip() for line in file.readlines()]\n",
    "\n",
    "print(f\"Vocabulary loaded with {len(vocabulary)} words.\")\n",
    "# Now we can create an instance of the OneHotVectoriser with the loaded vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can create an instance of the OneHotVectoriser with the loaded vocabulary\n",
    "\n",
    "first_onehot_vectoriser = OneHotVectoriser(vocabulary=vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thats it! Lets try it out by passing some text to the transform method! \n",
    "\n",
    "Lets verify a few things, and ensure that the input accepts texts and lists of texts. and also that its returning the right numpy arrays!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot vector shape: (1, 10000)\n",
      "One-hot vector type: <class 'numpy.ndarray'>\n",
      "-----\n",
      "[[1 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "vector_one = first_onehot_vectoriser.transform(\"The quick brown fox jumped over the log\")\n",
    "\n",
    "print(f\"One-hot vector shape: {vector_one.shape}\")\n",
    "print(f\"One-hot vector type: {type(vector_one)}\")\n",
    "print(\"-----\")\n",
    "print(vector_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-zero elements in the vector: 6\n"
     ]
    }
   ],
   "source": [
    "#we can also see how many elements of the vector are non-zero (should be equal to the number of unique words in the input text)\n",
    "print(f\"Number of non-zero elements in the vector: {np.count_nonzero(vector_one)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot vector shape: (2, 10000)\n",
      "One-hot vector type: <class 'numpy.ndarray'>\n",
      "-----\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function print(*args, sep=' ', end='\\n', file=None, flush=False)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can also pass a list of strings to the transform method\n",
    "vector_two = first_onehot_vectoriser.transform([\"The quick brown fox jumped over the log\", \"Slow and steady wins the race\"])\n",
    "print(f\"One-hot vector shape: {vector_two.shape}\")\n",
    "print(f\"One-hot vector type: {type(vector_two)}\")\n",
    "print(\"-----\")\n",
    "print(vector_two)\n",
    "print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets Use One-Hot-Encoding Vectoriser to create a VectorStore!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you followed along with the code above, you should now have a custom vectoriser in memory and it should be fully compatiable with the rest of the Package.\n",
    "\n",
    "We are now going to steal the second section of the oo_prototype_demo.ipynb script and build a VectorStore with the 'data/testdata.csv' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - No output directory specified, attempting to use input file name as output folder name.\n",
      "INFO - Processing file: data/testdata.csv...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35cc57eebaf649e9a7f2d5e5aa66009b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Gathering metadata and saving vector store / metadata...\n",
      "INFO - Vector Store created - files saved to testdata\n"
     ]
    }
   ],
   "source": [
    "from classifAI_API.indexers import VectorStore\n",
    "\n",
    "\n",
    "my_vector_store = VectorStore(\n",
    "    file_name=\"data/testdata.csv\",\n",
    "    data_type=\"csv\",\n",
    "    vectoriser=first_onehot_vectoriser, #or switch to the GcpVectoriser if you have it :)\n",
    "    batch_size=10,\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've build a vector store! Now to search it with a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>query_id</th><th>query_text</th><th>doc_id</th><th>doc_text</th><th>rank</th><th>score</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>&quot;Places with a vast delta&quot;</td><td>&quot;1085&quot;</td><td>&quot;The delta is vast.&quot;</td><td>0</td><td>2.0</td></tr><tr><td>0</td><td>&quot;Places with a vast delta&quot;</td><td>&quot;1041&quot;</td><td>&quot;The savanna is vast.&quot;</td><td>1</td><td>1.0</td></tr><tr><td>0</td><td>&quot;Places with a vast delta&quot;</td><td>&quot;1029&quot;</td><td>&quot;The desert is vast.&quot;</td><td>2</td><td>1.0</td></tr><tr><td>0</td><td>&quot;Places with a vast delta&quot;</td><td>&quot;1045&quot;</td><td>&quot;The delta is fertile.&quot;</td><td>3</td><td>1.0</td></tr><tr><td>0</td><td>&quot;Places with a vast delta&quot;</td><td>&quot;1100&quot;</td><td>&quot;The plateau is elevated.&quot;</td><td>4</td><td>0.0</td></tr><tr><td>0</td><td>&quot;Places with a vast delta&quot;</td><td>&quot;1040&quot;</td><td>&quot;The plateau is flat.&quot;</td><td>5</td><td>0.0</td></tr><tr><td>0</td><td>&quot;Places with a vast delta&quot;</td><td>&quot;1042&quot;</td><td>&quot;The tundra is cold.&quot;</td><td>6</td><td>0.0</td></tr><tr><td>0</td><td>&quot;Places with a vast delta&quot;</td><td>&quot;1037&quot;</td><td>&quot;The island is isolated.&quot;</td><td>7</td><td>0.0</td></tr><tr><td>0</td><td>&quot;Places with a vast delta&quot;</td><td>&quot;1036&quot;</td><td>&quot;The canyon is breathtaking.&quot;</td><td>8</td><td>0.0</td></tr><tr><td>0</td><td>&quot;Places with a vast delta&quot;</td><td>&quot;1038&quot;</td><td>&quot;The cliff is high.&quot;</td><td>9</td><td>0.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 6)\n",
       "┌──────────┬──────────────────────────┬────────┬─────────────────────────────┬──────┬───────┐\n",
       "│ query_id ┆ query_text               ┆ doc_id ┆ doc_text                    ┆ rank ┆ score │\n",
       "│ ---      ┆ ---                      ┆ ---    ┆ ---                         ┆ ---  ┆ ---   │\n",
       "│ i64      ┆ str                      ┆ str    ┆ str                         ┆ i64  ┆ f64   │\n",
       "╞══════════╪══════════════════════════╪════════╪═════════════════════════════╪══════╪═══════╡\n",
       "│ 0        ┆ Places with a vast delta ┆ 1085   ┆ The delta is vast.          ┆ 0    ┆ 2.0   │\n",
       "│ 0        ┆ Places with a vast delta ┆ 1041   ┆ The savanna is vast.        ┆ 1    ┆ 1.0   │\n",
       "│ 0        ┆ Places with a vast delta ┆ 1029   ┆ The desert is vast.         ┆ 2    ┆ 1.0   │\n",
       "│ 0        ┆ Places with a vast delta ┆ 1045   ┆ The delta is fertile.       ┆ 3    ┆ 1.0   │\n",
       "│ 0        ┆ Places with a vast delta ┆ 1100   ┆ The plateau is elevated.    ┆ 4    ┆ 0.0   │\n",
       "│ 0        ┆ Places with a vast delta ┆ 1040   ┆ The plateau is flat.        ┆ 5    ┆ 0.0   │\n",
       "│ 0        ┆ Places with a vast delta ┆ 1042   ┆ The tundra is cold.         ┆ 6    ┆ 0.0   │\n",
       "│ 0        ┆ Places with a vast delta ┆ 1037   ┆ The island is isolated.     ┆ 7    ┆ 0.0   │\n",
       "│ 0        ┆ Places with a vast delta ┆ 1036   ┆ The canyon is breathtaking. ┆ 8    ┆ 0.0   │\n",
       "│ 0        ┆ Places with a vast delta ┆ 1038   ┆ The cliff is high.          ┆ 9    ┆ 0.0   │\n",
       "└──────────┴──────────────────────────┴────────┴─────────────────────────────┴──────┴───────┘"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_search_results = my_vector_store.search(\"Places with a vast delta\")\n",
    "\n",
    "onehot_search_results\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEMO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
