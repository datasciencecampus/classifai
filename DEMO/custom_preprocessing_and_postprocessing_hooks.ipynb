{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VectorStore pre- and post- processing logic with <i>Hooks</i>ü™ù"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook provides a guide on how to implement custom, user-defined pre- and post-processing 'hooks'. Hooks provide a way to modify the traditional data flow of the ClassifAI package so that you might, for example:\n",
    "\n",
    "- Remove punctuation from input queries before the VectorStore search process begins,\n",
    "- Capitalising all text in an input query to the Vectorstore search process,\n",
    "- Deduplicate results based on the doc_id column so that duplicate knowledgebase entries are not returned,\n",
    "- Prevent users of the package from retrieving certain documents in your vectorstore,\n",
    "- Removing hate speech from any input text.\n",
    "\n",
    "\n",
    "Hooks work by defining functions that operate on the input and output dataclasses of each of our VectorStore functions/methods.\n",
    "\n",
    "<b>Key Sections:</b>\n",
    "- a recap of how the dataclasses for the VectorStore work, and how they ensure the proper flow of data in our package,\n",
    "- how hooks can be implemented by working with the dataclass objects,\n",
    "- examples of several different hook implementations, some of which were already mentioned above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap of VectorStore Dataclasses\n",
    "\n",
    "The majority of the following points are already covered in the recommended first notebook demo, [general_workflow_demo.ipynb](./general_workflow_demo.ipynb). So if you are unfamiliar with the package, that is a good place to start before this notebook, and for an intro to the VectorStore, its methods, and how it works with dataclasses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ClassifAI uses Pandas dataframe-like dataclasses to specify what data need to be passed as input to the VectorStore methods/functions, and what data can be expected to be returned by those methods\n",
    "\n",
    "The **VectorStore** class, responsible for performing different actions with your data, has **three key methods/functions**:\n",
    "\n",
    "1. **`search()`**  \n",
    "    - Takes in a body of text and searches the vector store for semantically similar knowledgebase samples.\n",
    "\n",
    "2. **`reverse_search()`**  \n",
    "    - Takes in document IDs and searches the vector store for entries with those IDs.\n",
    "\n",
    "3. **`embed()`**  \n",
    "    - Takes in a body of text and uses the vectoriser model to convert the text into embeddings.\n",
    "\n",
    "---\n",
    "\n",
    "For each of these three core methods, we have created an **input dataclass** and an **output dataclass**. These dataclasses define pandas-like objects that specify what data needs to be passed to each method and also perform runtime checks to ensure you've passed the correct columns in a dataframe to the appropriate VectorStore method.\n",
    "\n",
    "For example, the figure below illustrates the input and output dataclasses of the `VectorStore.search()` method:\n",
    "\n",
    "![VectorStore Search Dataflow](./files/vectorstore_search_dataflow.svg)\n",
    "\n",
    "This shows that the `VectorStore.search()` method expects:\n",
    "- An **input dataclass object** with columns `[id, query]`. \n",
    "- To output an **output dataclass object** with columns `[query_id, query_text, doc_id, doc_text, rank, score]`.\n",
    "\n",
    "The use of these dataclasses both helps the user of the package to understand what data needs to be provided to the Vectorstore and how a user should interact with the objects being returned by these VectorStore functions. Additionally, this ensures robustness of the package by checking that the correct columns are present in the data before operating on it. \n",
    "\n",
    "The reverse_search() and embed() VectorStore functions have their own input and output data classes with their own validity column data checks. The names of each set are intuitively:\n",
    "| **VectorStore Method**       | **Input Dataclass**         | **Output Dataclass**        |\n",
    "|-------------------------------|-----------------------------|-----------------------------|\n",
    "| `VectorStore.search()`    | `VectorStoreSearchInput`    | `VectorStoreSearchOutput`   |\n",
    "| `VectorStore.reverse_search()` | `VectorStoreReverseSearchInput` | `VectorStoreReverseSearchOutput` |\n",
    "| `VectorStore.embed()`     | `VectorStoreEmbedInput`     | `VectorStoreEmbedOutput`    |\n",
    "\n",
    "Users of the package can use the schema of each of these input and output dataclasses to understand how to interface with these main methods of the VectorStore class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hooks and custom dataflows\n",
    "\n",
    "We have implemented 'hooks' where users can write a function that will manipulate the content of a dataclasses object before or after it passes through the VectorStore. \n",
    "\n",
    "As long as your custom hook function takes as input an instance of a dataclass, and outputs a valid instance of the same type, then your custom function should run as a part of the end to end VectorStore process.\n",
    "\n",
    "For example: you might want to preprocess the input to the VectorStore.search() method to remove punctuation from the texts:\n",
    "\n",
    "![VectorStore Search Dataflow](./files/search_spellcheck_hook.svg)\n",
    "\n",
    "\n",
    "\n",
    "In a later part of the demo, we showcase how to implement this punctuation removing function, and apply it to the vectorstore. The important concept here is that the hook function takes in a `VectorStoreSearchInput` object, and outputs a valid `VectorStoreSearchInput` object. \n",
    "\n",
    "\n",
    "This can then be attached to a VectorStore to run every time the VectorStore search method is called. You can also apply other hooks to other dataclasses and their respective VectorStore methods and chain togtether these custom operations that manipulate the input and output dataclasses of the VectorStore methods. \n",
    "\n",
    "For example, implmenting 2 hooks for the input and output dataclasses of the VectorStore search method would provide a dataflow:\n",
    "\n",
    "![End to end Search with 2 hooks](./files/pre_and_post_search_hooks.png)\n",
    "\n",
    "\n",
    "The above diagram shows a case where two hooks would be implemented: One that operates on the dataclass `VectorStoreSearchInput`that is passed to the Vectortore search method; and a second hook operating on the `VectorStoreSearchOutput` dataclass that is returned from the VectorStore search method.\n",
    "\n",
    "\n",
    "<b>Hooks can perform pretty much any operation, as long as they accept and return a valid dataclass object - we hope that this provides a lot of freedom to users to be able to transform and manipulate data as needed using ClassifAI.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Hook implementations\n",
    "\n",
    "This section now shows how to define your hook functions, and inject them into the VectorStore so that the hooks run when the corresponding method is called.\n",
    "\n",
    "Specifically we'll look at:\n",
    "- a pre-processing function that removes punctuation from input user queries,\n",
    "- a post-processing function removes results rows that have duplicate ids to other rows of the results.\n",
    "\n",
    "- We will then make a final post-processing function that injects additional SOC definition data to the VectorStore results dataframe and show how this can be chained together with the deduplication code, to make a multi-step post-processing function!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-requisite\n",
    "\n",
    "If you are new to the package, its recommended to follow through the ```general_workflow.ipynb``` notebook tutorial first. That interactive DEMO will showcase the core features of the ```ClassifAI package```. This current notebook provides examples of how to modify the flow of data which is initially described in the general_workflow.ipynb notebook.\n",
    "\n",
    "Check out the ClassifAI repository DEMO folder for all our notebook walkthrough tutorials including those mentioned above:\n",
    "\n",
    "https://github.com/datasciencecampus/classifai/tree/main/DEMO \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We recommend making a new virtual environment to try out the demo, for example: (may differ slightly depending on your OS)\n",
    "\n",
    "## if using pip\n",
    "# python -m venv .venv\n",
    "# source .venv/Scripts/activate\n",
    "# pip install \"git+https://github.com/datasciencecampus/classifAI\"\n",
    "# pip install \"classifAI[huggingface]\"\n",
    "\n",
    "## if using uv\n",
    "# uv venv\n",
    "# source .venv/Scripts/activate\n",
    "# uv pip install \"git+https://github.com/datasciencecampus/classifAI[huggingface]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal vectorstore setup\n",
    "\n",
    "We can start by loading a normal vectorstore up with no additional preprocessing/hooks. We can use one of our fake example known datasets is known to have several rows of data with the same ID value. (You can get this from the github repo at the folder location specified in the code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifai.indexers import VectorStore\n",
    "from classifai.vectorisers import HuggingFaceVectoriser\n",
    "\n",
    "vectoriser = HuggingFaceVectoriser(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "my_vector_store = VectorStore(\n",
    "    file_name=\"data/fake_soc_dataset.csv\",\n",
    "    data_type=\"csv\",\n",
    "    vectoriser=vectoriser,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code uses our dataclasses to set up some data to pass to the VectorStore search method, notice that:\n",
    " * an exclaimation mark in the query (that in some cases we may want to sanitise) is shown in the results. \n",
    " * Also the results for the below query should also show several rows with the same ```'doc_id'``` value (because our example data file had multiple entries with the same id label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifai.indexers.dataclasses import VectorStoreSearchInput\n",
    "\n",
    "input_data = VectorStoreSearchInput({\"id\": [1], \"query\": [\"a fruit and vegetable farmer!!!\"]})\n",
    "\n",
    "my_vector_store.search(input_data, n_results=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making pre- and post- processing hooks \n",
    "\n",
    "So lets write some functions that will remove punctuation on the user's input query, before the main logic of the Vectorstore.search() method begins, and remove rows with duplicate IDs from the results dataframe just before the results are retutned from the Vectorstore.search() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = VectorStoreSearchInput({\"id\": [1], \"query\": [\"a fruit and vegetable farmer!!!\"]})\n",
    "\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "from classifai.indexers.dataclasses import VectorStoreSearchOutput\n",
    "\n",
    "\n",
    "def remove_punctuation(input_data):\n",
    "    # we want to modify the 'texts' field in the input_data pydantic model, which is a list of texts\n",
    "    # this line removes punctuation from each string with list comprehension\n",
    "    sanitized_texts = [x.translate(str.maketrans(\"\", \"\", string.punctuation)) for x in input_data[\"query\"]]\n",
    "\n",
    "    input_data[\"query\"] = sanitized_texts\n",
    "\n",
    "    # Return the dictionary of input data with desired modified values at each desired key\n",
    "    return input_data\n",
    "\n",
    "\n",
    "def drop_duplicates(input_data):\n",
    "    # we want to depuplicate the ranking attribute of the pydantic model which is a pandas dataframe\n",
    "    # specifically we want to drop all but the first occurrence of each unique 'doc_id' value for each subset of query results\n",
    "    input_data = input_data.drop_duplicates(subset=[\"query_id\", \"doc_id\"], keep=\"first\")\n",
    "\n",
    "    # BE CAREFUL: drop_duplicates returns an object of type DataFrame, not VectorStoreSearchOutput so we need to convert back  to that type after this operation\n",
    "    input_data = VectorStoreSearchOutput(input_data)\n",
    "\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding our Hooks to the VectorStore\n",
    "\n",
    "Now when we initialise the Vectorstore we can declare our custom functions in the hooks dictionary.\n",
    "\n",
    "The Vectorstore codebase looks for specifically named dictionary entries in the Hooks dictionary, to decide what pre and post processing hooks to run. There are hooks for each major methods of VectorStore class.\n",
    "\n",
    "Each dictionary entry uses the method name of the class and '_preprocessor' or '_postprocessor' appended to the name. Currenlty the implemented method hooks are:\n",
    "\n",
    "- for the VectorStore class:\n",
    "    * search_preprocess\n",
    "    * search_postprocess\n",
    "    * reverse_search_preprocess\n",
    "    * reverse_search_postprocess\n",
    "\n",
    "\n",
    "For our case in this excercise, we are implementig the search_preprocessor and search_postprocessor methods in the VectorStore.\n",
    "\n",
    "\n",
    "However if we could also add to add a preprocessing or postprocessing hook to a VectorStore reverse search method in a similar manner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vector_store_with_hooks = VectorStore(\n",
    "    file_name=\"data/fake_soc_dataset.csv\",\n",
    "    data_type=\"csv\",\n",
    "    vectoriser=vectoriser,\n",
    "    overwrite=True,\n",
    "    hooks={\n",
    "        \"search_preprocess\": remove_punctuation,\n",
    "        \"search_postprocess\": drop_duplicates,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our hooks will run with the VectorStore search method\n",
    "\n",
    "\n",
    "Now we've passed our desired additional functions to our VectorStore initialisation and those hook should run accordingly - lets see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = VectorStoreSearchInput({\"id\": [1], \"query\": [\"a fruit and vegetable farmer!!!\"]})\n",
    "\n",
    "my_vector_store_with_hooks.search(input_data, n_results=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oops!\n",
    "\n",
    "Notice how in the above dataframe, the rank column now leaps over some values in each ranking. \n",
    "\n",
    "We didn't reset the ranking values, per query, when we removed duplicate rows...\n",
    "\n",
    "lets redo that now in a new function and hook it up to our preprocessing hook.\n",
    "\n",
    "\n",
    "##### Notice how this time, we changed the name of our paramter in our custom hook functions, thats because it doesn't matter what the name of the parameter is, we just need to understand that it will take in one argument - the pydantic object associated with the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicates_and_reset_rank(input_object):\n",
    "    # Remove duplicates based on 'query_id' and 'doc_id'\n",
    "    input_object = input_object.drop_duplicates(subset=[\"query_id\", \"doc_id\"], keep=\"first\")\n",
    "\n",
    "    # Reset the rank column per query_id using .loc to avoid SettingWithCopyWarning\n",
    "    input_object.loc[:, \"rank\"] = input_object.groupby(\"query_id\").cumcount()\n",
    "\n",
    "    # convert the DataFrame back to the pydantic validated object\n",
    "    input_object = VectorStoreSearchOutput(input_object)\n",
    "\n",
    "    return input_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the cell below, you can see another way to set hooks - by directly accessing the hooks attribute of a running vectorstore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and lets access the hooks directly from the vector store instance to modify them\n",
    "my_vector_store_with_hooks.hooks[\"search_postprocess\"] = drop_duplicates_and_reset_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### done - now lets run that query again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vector_store_with_hooks.search(input_data, n_results=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This of course still works well when you pass multiple queries as we wrote it to separate on query_id column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_input_data = VectorStoreSearchInput(\n",
    "    {\n",
    "        \"id\": [1, 2],\n",
    "        \"query\": [\"a fruit and vegetable farmer!!!\", \"Digital marketing@\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "my_vector_store_with_hooks.search(multi_input_data, n_results=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Hooks to a VectorStore when loading from filespace\n",
    "\n",
    "ClassifAI allows you to create your VectorStore once, and then save it to file space so that it can be loaded back in later and reused - <it>without</it> having to create all the vectors again.\n",
    "\n",
    "If you've followed through with the above code cells you may have noticed that every time we've instantiated a VectorStore it has saved a new folder to filespace (overwriting each time).\n",
    "\n",
    "Use the VectorStore.from_filespace() class method to load the VectorStore back into memory.\n",
    "\n",
    "<b>Important:</b> any hooks you applied in previous sessions are not saved to the filespace (it can be difficult to serialise functions). The from_filespace() class method has a hook parameter, similar to the VectorStore constructor we saw earlier. When loading from filespace in this way, you must reaplly the hook functions using this parameter or by setting the attribute after loading, as seen above.\n",
    "\n",
    "\n",
    "The following code cells show an example of loading the VectorStore, that was saved to filespace in this demo, back into memory and reapply the hooks on instantiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can see we've reused the vectoriser and hooks from before\n",
    "\n",
    "\n",
    "reloaded_vector_store = VectorStore.from_filespace(\n",
    "    folder_path=\"./fake_soc_dataset/\",  # YOU MAY NEED TO CHANGE THIS LINE TO THE CORRECT PATH\n",
    "    vectoriser=vectoriser,\n",
    "    hooks={\n",
    "        \"search_preprocess\": remove_punctuation,\n",
    "        \"search_postprocess\": drop_duplicates,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then continue to use the vectorstore as seem earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_vector_store.search(input_data, n_results=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Injecting Data into our classification results with a hook\n",
    "\n",
    "What if we had some additional context information that we wanted to add in our pipeline. It could be some official taxonomy definitions about our doc_id labels, such as SIC or SOC code definitions.\n",
    "\n",
    "We may want to inject this extra information that's not directly stored as metadata in the knowledgebase, so that a downstream component (such as a RAG agent) can use the additional information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### But we also want keep our existing hook logic that removes punctuation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "official_id_definitions = {\n",
    "    \"101\": \"Fruit farmer: Grows and harvests fruits such as apples, oranges, and berries.\",\n",
    "    \"102\": \"iry farmer: Manages cows for milk production and processes dairy products.\",\n",
    "    \"103\": \"nstruction laborer: Performs physical tasks on construction sites, such as digging and carrying materials.\",\n",
    "    \"104\": \"rpenter: Constructs, installs, and repairs wooden frameworks and structures.\",\n",
    "    \"105\": \"ectrician: Installs, maintains, and repairs electrical systems in buildings and equipment.\",\n",
    "    \"106\": \"umber: Installs and repairs water, gas, and drainage systems in homes and businesses.\",\n",
    "    \"107\": \"ftware developer: Designs, writes, and tests computer programs and applications.\",\n",
    "    \"108\": \"ta analyst: Analyzes data to provide insights and support decision-making.\",\n",
    "    \"109\": \"countant: Prepares and examines financial records, ensuring accuracy and compliance with regulations.\",\n",
    "    \"110\": \"acher: Educates students in schools, colleges, or universities.\",\n",
    "    \"111\": \"rse: Provides medical care and support to patients in hospitals, clinics, or homes.\",\n",
    "    \"112\": \"ef: Prepares and cooks meals in restaurants, hotels, or other food establishments.\",\n",
    "    \"113\": \"aphic designer: Creates visual concepts for advertisements, websites, and branding.\",\n",
    "    \"114\": \"chanic: Repairs and maintains vehicles and machinery.\",\n",
    "    \"115\": \"otographer: Captures images for events, advertising, or artistic purposes.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_id_definitions(input_data):\n",
    "    # Map the 'doc_id' column to the corresponding definitions from the dictionary\n",
    "    input_data.loc[:, \"id_definition\"] = input_data[\"doc_id\"].map(official_id_definitions)\n",
    "\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can now combine this with our deduplicating hook in a new function that runs both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_results(validated_input_object):\n",
    "    # First, remove duplicates and reset rank\n",
    "    validated_input_object = drop_duplicates_and_reset_rank(validated_input_object)\n",
    "\n",
    "    # Then, add ID definitions\n",
    "    validated_input_object = add_id_definitions(validated_input_object)\n",
    "\n",
    "    # Return the final processed dataframe\n",
    "    return validated_input_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lets once again update the postprocessing hook on our vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vector_store_with_hooks.hooks[\"search_postprocess\"] = process_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### and lets try the search again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_input_data = VectorStoreSearchInput(\n",
    "    {\n",
    "        \"id\": [1, 2],\n",
    "        \"query\": [\"a fruit and vegetable farmer!!!\", \"Digital marketing@\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "my_vector_store_with_hooks.search(multi_input_data, n_results=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a few null values in that last output because our demo list of extra data wasn't exhaustive, but where an ID does match our 'official_id_definitions' data we see the data being added correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roundup\n",
    "\n",
    "- We wrote and combined several hooks on the Vectorstore class to:\n",
    "    - remove punctuation from queries before the  ```VectorStore.search()``` method is executed\n",
    "    - remove duplicates from the results list per query ranking and fixed the ranking\n",
    "    - injected data into our dataflow outside of constructing a vectorstore\n",
    "    - chained several Vectorstore.search() postprocessing steps together into one function that calls other functions\n",
    "\n",
    "- In this scenario we effectively showed how to deduplicate the rows of the results dataframe and add additional context columns of information in the form of the id_definitions. Hopefully, it is clear that you can add many pre- or post-processing steps this way, or by writing all steps in one big function - Hooks give you the flexibility and choice here.\n",
    "\n",
    "- Hooks let you disrupt the normal flow of data in the VectorStores. In this case we just had a small amount of dictionary data being added in, however the hooks allow for more complex scenarios:\n",
    "    - using a 3rd party API to do automated corrective spell checking before passing your queries to the search method\n",
    "    - making an SQL query call to a database to get the extra information you want to inject in each row\n",
    "    - handle errors when the API or database fails and choose what should be returned in these cases\n",
    "\n",
    "\n",
    "### Key Takeaway:\n",
    "- When writing your custom hook, remember that your custom hook function should take a single argument - a specific dataclass, and it should output that same dataclass with the modified rows, columns and values. How you implement the logic to update the values is up to you but it must satify the requirements of that dataclass type.\n",
    "\n",
    "- Depending on which kind of hook you are writing, you need to adhere to the rules of the corresponding dataclass for that hook. For example, in the above demonstration we focused on writing search() preprocessing hooks that manipulate the VectorStoreSearchInput dataclass. However, if you were to write a reverse_search() preprocessing hook, your hook function would need to manipulate the VectorStore<b>Reverse</b>SearchInput dataclass, which has a different set of rules for the columns that must be present and the datatypes of those columns. This extends to each of the hook categories, each of which corresponds to a specific dataclass with its own ruleset.\n",
    "\n",
    "\n",
    "### Next Steps and Challenges:\n",
    "\n",
    "#### We focused soley on showcasing pre- and post-processing hooks for the VectorStore search method in this notebook:\n",
    "\n",
    "- See if you can implement some pre- and post- processing hooks for the VectorStore reverse search method:\n",
    "    - try adding a new column of data to the reverse search results \n",
    "    - make it so that if the user tries to reverse search for a specific ID that is 'secret' then that row is removed from the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classifai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
